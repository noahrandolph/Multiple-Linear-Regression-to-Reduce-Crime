---
title: "Lab 4: Reducing Crime"
author: "Asha Anju, Anamika Sinha, Noah Randolph"
date: "8/14/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Societies have long been interested in studying crime rate. Factors that influence crime rate have been debated and researched with data in many different studies. Although specific factors may have varying weightage for an individual  city or area, there are some  factors that have broad acceptance. Economic conditions like poverty, unemployment rate are considered to increase crime. Biographic factors


Why this appeals political campaigns? Communities are made up of different groups with apparently different interests regarding crime. Local businesses may be interested in tackling crimes such as burglary from shops or shop stealing. They may also have an interest in having something done about manifestations of local disorder (e.g. public drunkenness, graffiti, loitering, truancy, etc). In rural areas, farmers may feel affected by crimes such as stock theft, theft of farm vehicles, machinery or tools, damage to farm property, or illegal use outsiders of land, water or other resources of farms. Research suggests that farm crime costs dearly to farmers and the local economy.

Local residents may be interested in dealing with home burglaries, damage to residential property, drugs, and assaults on the street. They may also feel uneasy at manifestations of disorder such as truancy, drunks and vagrants on the streets, rubbish and litter in the area, gardens and public areas in bad condition, noisy neighbours, and signs of vandalism or deliberate damage to private and public property.

## Load Data 

We first load the data and note any anomalies, such as missing values, top-coded or bottom-coded variables, or not-applicable values.

```{r load data}
library(sandwich)
library(lmtest)
library(car)
library(stargazer)
library(MASS)

#setwd("~/Documents/W203_Statistics/Labs/Lab_4/Lab4Repository")
CrDat = read.csv("crime_v2.csv")
attach(CrDat)
```



##  Exploratory Data Analysis
We begin with a summary of the data.
```{r}
summary(CrDat)
nrow(CrDat)
ncol(CrDat)
```
##Observations: 
There are 90 observations across 25 variables. There are no missing values and the data in each variable make sense given the variable types, except for values in _probsen_ and _probconv_, which both show proportions that are greater than 1. This may be due to differences in ways the variable is reported from across the state. We will note this but would like to keep them in our analysis as they may have significant information. We also note that the maximum density is 8.8 people per square mile which indicates that we may be looking at a rural state. The crime rate proportions are low decimal values, so we will rescale it later to improve interpretation. Also, _avgsen_ has a maximum of 20 days which suggests that we have a vast majority of petty crimes. We notice a very high value of 2177.1 dollars for _wageser_ which is an extreme outlier since difference between this value and the third quartile is greater than three times the interquartile range. 

##Model proposal
Our dataset has _probsen_, _probconv_, _probarr_ , _mix_ , _avgsen_, _police_  variables which represent the criminal justice system. We have variables like _wage_ & _tax_ which are representative of economic conditions. We also have _pctmin_, _ymale_, _density_, _urban_ variables which fall under demographic factors. There are three indicator variables representing regions(west, central) and cities(urban). 

Crime rate depends on the effectiveness of the criminal justice system and economic factors. Criminal justice systems reduce crime through deterrence. Therefore increases in police, arrests, convictions, crime sentencing, and prison sentence length should reduce crime rate. Therefore, we explore these variables.

We first look at the response variable, _crime_, representing the number of each counties' crimes committed per person. The common way to report crimes is per 1000 people, so we'll do that here for readability. 

```{r fig.height = 4, fig.width = 4}
scaledcrime = crime*1000
hist(scaledcrime, breaks = 20, main = "County Crime Rates", 
     xlab = "crimes committed per 1000 people")
```

Then we take a look at other key criminal justice variables. To make police consistent with _crime_, we scale _police_ as well.

```{r fig.height=16, fig.width=12}
scaledpolice = police*1000
par(mfrow=c(5,2))
hist(scaledpolice, breaks = 20, main = "Police Per Capita",
     xlab = "police per capita", cex.main = 1.5)
hist(probarr, breaks = 16, 
     main = "Proportion of County Crimes Resulting in Arrests",
     xlab = "Proportion of Crimes Resulting in Arrests", cex.main = 1.5)
hist(probconv, breaks = 10, main = "Proportion Being Convicted After Arrest",
     xlab = "Proportion", cex.main = 1.5)
hist(probsen, breaks = 20, main = "Proportion Being Sentenced After Conviction",
     xlab = "Proportion", cex.main = 1.5)
hist(mix, breaks = 20, main = "Ratio of Face-to-Face/All Other Crime",
     xlab = "Ratio", cex.main = 1.5)
hist(tax, breaks = 20, main = "Tax Per Capita",
     xlab = "Tax", cex.main = 1.5)
hist(density, breaks = 20, main = "Density",
     xlab = "people per square mile", cex.main = 1.5)
hist(ymale, breaks = 20, main = "Propotion of County Males Between 15 And 24 years.",
     xlab = "Proportion", cex.main = 1.5)
hist(pctmin, breaks = 20, main = "Proportion Of Minority Or Nonwhite",
     xlab = "Proportion", cex.main = 1.5)
```



### Observations:
Response variable$\\$ 
_crime_: The histogram shows a positive skew. Presence of one outlier is noted. Because of the positive skew, we will do a log transformation of this variable.  
*Criminal justice variables*  
_police_: The histogram shows a positive skew. We have one outlier which is county 115. Police per capita, _police_, should have negative influence on county crime rates, since their presence is generally thought of as a deterence.  consider a log transformation of this variable. $\\$
_probarr_: The histogram shows a slight negative skew. This variable is likely to be correlated to police since more police will lead to more arrests and vice versa. $\\$
_probsen_: The histogram shows a slight positive skew. Also, presence of two outliers is noted.  We see a probability value of greater than 1. Interestingly, this belongs to county 115, the same county which has the police outlier. $\\$
_probconv_: The histogram shows a high positive skew. We see a probability value of greater than 1 for ten counties. We note an outlier  with value 2.12 in county 185. This county also has an extreme outlier in _wageser_ of \$2177.06. As mentioned before, we could not find a reasonable explaination for this. So we decided to include these in our analysis. $\\$
_mix_: The histogram shows a high positive skew. $\\$
_avgsen_: From the initial summary, due to the low number of maximum days, we think that this variable is unlikely to deter crime. $\\$

Economic variables$\\$
Wage would be a good economic indicator but in our dataset, wage is broken up into eight different variables based on sector. In the absence of sector weights, it is difficult to create a meaningful average variable. We tried various ways to interpret the given information by taking an average of all the wage variables and also the wage range in each county to understand wage effect on crime.

_tax_: Tax revenue per capita is a good indicator of the financial health of a county. The histogram shows a positive skew. Also, presence of an outlier is noted which is county 55. We did not find anything noteworthy in this county.

Demographic variables$\\$
_density_: The histogram has a strong positive skew, reflecting a few urban areas in the state. As mentioned before, the maximum density is only eight people per square mile. $\\$
_ymale_: This histogram also has a strong positive skew. It has an outlier in county 133. We did not find anything worth noting in this county.$\\$
_pct\_min_: The histogram has somewhat of a uniform distribution with a decrease on the right end. 


Indicator variables$\\$
_urban_: We have 8 counties in this region. $\\$
_west_: There are 34 counties that belong to West region.$\\$
_central_: 21 counties fall in this region. 


Following the first stage of data analysis we perform a log transformation of crime and density and plot histograms.

```{r fig.width=12}
par(mfrow=c(1,2))
hist(log(scaledcrime), main="Log of Crime", xlab=NULL, breaks=20)
hist(log(density), main="Log of Density", xlab=NULL, breaks=20)
```

#Observations:
_log(scaledcrime)_: The log transformation has made the distribution quite normal. This will help ensure that the errors of the model are normal (i.e. CLM assumption 6).$\\$
_log(density)_: The log transformation of density has helped with the normalty of the distribution  as well.

#Correlations
We examine the relationship between crime rate and potentially deterrent criminal justice variables. As mentioned before, _police_ and _probarr_ are likely to be highly correlated, since police are the ones making arrests, so we include only one out of the two. _mix_ most likely has an associative relationship to crime and will not be a deterrent, so we exclude it.

```{r}
scatterplotMatrix(~ log(scaledcrime) + log(scaledpolice) + probconv + probsen)
```

#Observations:
Contrary to our expectation, we see a positive relationship between _log(scaledpolice)_ and _log(scaledcrime)_. This suggests that police may be the result of high crime rate rather than a cause of low crime rate. Therefore, it will not be a key variable of interest. Both _probsen_ and _probconv_ have the expected negative relationship with crime rate, meaning that they are potentially deterrent factors. 

```{r}
scatterplotMatrix(~ log(scaledcrime) + log(density) + pctmin + log(ymale) + log(tax))
```

##Observations:
We see a strong positive relationship between _log(density)_ and _log(scaledcrime)_, which is consistent with the common notion of high crime rate in urban areas. The association between _pctmin_ and _log(scaledcrime)_ is less clear, with an initial rise, then a reduction as _pctmin_ increases on the x-axis. Even after the log transformation, _log(ymale)_ still has a high positive skew and therefore too much clustering to make sense of the relationship with crime rate. The same is true for _log(tax)_. Furthermore, we expected to see a negative relationship with tax revenue per capita as a proxy for income levels. Since it's positive, we rule out tax as a key variable of interest as it relates to reducing crime rates.

#### Model 1
Based on the exploratory data analysis and underlying intuition about crime relationships, our initial proposed model specification and coefficient expectations are:
_log(density)_: since this variable shows the strongest linear relationship with _log(scaledcrime)_ and is consistent across its range, we include this as an associative variable to avoid significant omitted variable bias in our key variables of interest.$\\$
_probconv_ : our intuition that an increase in conviction helps reduce crime rate is supported by the scatterplot in our EDA. While _probsen_ showed a negative relationship with _crime_ in the scatterplot analysis, it is likely to be key deterrent as the maximum average length of sentencing is so low (20 days). 

```{r}
model1 = lm(log(scaledcrime) ~ probconv  + log(density))
```

#### Testing the validity of the 6 assumptions of the CLM
**CLM 1 - A linear model**
The model is specified such that the dependent variable is a linear function of the explanatory variables. $\\$
Is the assumption valid? Yes.$\\$
Response: No response required.

**CLM 2 - Random Sampling**
Given that we have a dataset of 90 counties from an unknown location, and we do not know how the data was collected and if the data collection was consistent among the counties, this assumption is uncertain. Additionally the structure of one observation representing each county further confounds the assumption of randomly observed variables. A true random sample would take observations at random from the unaggregated level. $\\$
Is the assumption valid? Not clear.$\\$
Response: We proceed with the analysis.

**CLM 3 - Multicollinearity**
As a quick test of the multicollinearity condition, we check the correlation of the three explanatory variables and their Variance Inflation Factors (VIF):

```{r}
CrDat$logdensity = log(density)
X = data.matrix(subset(CrDat, select=c(logdensity, probconv)))
cor(X)
vif(model1)
```

The two explanatory variables are not perfectly correlated and the VIFs are low (i.e. less than 4), so there is no perfect multicollinearity of the independent variables.$\\$
Is the assumption valid? Yes $\\$
Response: No response required.

***CLM 4 - Zero-Conditional Mean***
To analyze whether there is a zero-conditional mean of the residuals across the explanatory variables in model 1, we plot the residuals against the fitted values with the predicted conditional mean spline line across fitted values.
```{r}
plot(model1, which=1)
```

The plot indicates little evidence that the zero-conditional mean assumption doesn\'t hold. The red spline line on the residuals versus fitted values plot is fairly flat.$\\$
Is the assumption valid? Yes$\\$
Response: No response required

**CLM 5 - Homoscedasticity**
To determine whether the variance of the error is fixed for all model 1 explanatory variables, we view the scale-location plot. 

```{r}
plot(model1, which = 3)
bptest(model1)
```

The scale-location plot shows some evidence of heteroskedasticity, as seen by the red spline line curvature. The Breusch-Pagan shows a rejection of the null hyposthesis of homoskedasticity, with a p-value less than $\alpha$ = 0.05.

Is the assumption valid? No.$\\$
Response: Use robust standard errors.

**CLM 6 - Normality of residuals**
To determine whether there is normality of the residuals we use a Q-Q plot of the residuals and simply visually observe whether there is normality.

```{r}
plot(model1, which = 2)
```

The Q-Q plot shows deviation from normality on the positive end. 

Is the assumption valid? No.$\\$
Response: Despite the distribution of model 1 residuals showing non-normality, since we have a large sample size of 90, we can rely on the central limit theorem to satisfy this assumption.

```{r}
coeftest(model1, vcov = vcovHC)
```
The results shows that a 1 unit increase in proportion of conviction is associated with a decrease in crime per 1000 people of 37% $((e^{-0.466}-1)*100)$. For every 1% increase in density, the crime per 100 people go up by approximatley 0.44%. 

#### Model 2
Building on our initial model, we include variables that are associative but less likely to introduce bias. 
_probsen_: An increase in sentencing rates is associated wth a reduction in crime rate as seen from the scatterplot in our EDA.
_pctmin_:In real world, poverty, minority population and crime rates are interlinked. We include _pctmin_ in our model in lieu of an economic indicator for low income communites.

```{r}
model2 = lm(log(scaledcrime) ~ probconv + log(density)+ probsen +pctmin)
AIC2 = AIC(model2)
plot(model2)
vif(model2)
```




**Noting CLM assumption differences from Model 1** 
The Q-Q plot shows deviation from normality on both the negative end and the positive end. So we continue to rely on the Central Limit Theorem. 

The zero conditional mean assumption holds except for the left end of the plot where we have only one data point. The Scale-Location plot shows reduced evidence of heteroskedasticity. So we continue to use robust standard errors. The residual vs. leverage plot has one data point with a cook's distance above 1. The lone point is county 51, which is the only one with a probability of sentencing above 1. 

```{r}
detach(CrDat)
CrDat1 <- CrDat[-c(51),]
attach(CrDat1)
model2_alt = lm(log(crime) ~ probconv + log(density) + probsen + pctmin)
plot(model2_alt, which = 1)
detach(CrDat1)
```

When we ran the model after removing this data point, zero conditional mean and homoskedasticity assumptions hold and the model estimates do not change significantly. We are keeping county 51 in our model as this is a real data point.


```{r}
coeftest(model2, vcov = vcovHC)
```
The results shows that a 1 unit increase in proportion of conviction is associated with a decrease in crime per 1000 people of 42% $((e^{-0.55}-1)*100)$. For every 1% increase in density, the crime per 100 people go up by approximatley 0.39%. A 1 unit increase in proportion of sentencing is associated with a decrease in crime per 1000 people of 69.2%. Finally a 1 percentage point increase in percentage of minorities is associated with a increase in crime per 1000 people of 1.2%. 


#### Model 3
In this model, we include the remaining variables excluding _police_ and the 9 wage variables. As previously mentioned, we believe police per capita is an outcome of the crime rate since they are positively related. We are unable to create a meaningful wage variable without employment information to combine the sector wage variables into a weighted average. 

```{r}
attach(CrDat)
model3 = lm(log(scaledcrime) ~ probconv + probsen +  log(density) + pctmin + probarr + ymale + avgsen +  mix  + central + west + tax)
AIC3 = AIC(model3)
plot(model3)
vif(model3)
summary(model3)
```

**Noting CLM assumption differences from Model 2** 

Once again, the zero conditional mean assumption holds except for the left end of the plot where we have only one data point. The Scale-Location plot shows greater heteroskedasticity than model 2. So we continue to use robust standard errors.  The influence of county 51 on the model has reduced (Cook's distance < 1) as seen in the residual vs. leverage plot. 

The Q-Q plot shows deviation from normality on both the negative end and the positive end. So we continue to rely on the Central Limit Theorem. 

```{r}
coeftest(model3, vcov = vcovHC)
```


## Comparison of Models

```{r}
# Compute Akaike information criterion (AIC)
AIC1 = AIC(model1)
AIC2 = AIC(model2)
AIC3 = AIC(model3)

# Adjust standard errors
cov1 = vcovHC(model1)
robust_se1 = sqrt(diag(cov1))
cov2 = vcovHC(model2)
robust_se2 = sqrt(diag(cov2))
cov3 = vcovHC(model3)
robust_se3 = sqrt(diag(cov3))

# Adjust F statistic
wald_results <- waldtest(model1, vcov = cov1)

stargazer(model1, model2, model3, type = 'text', intercept.bottom = FALSE,
          se        = list(robust_se1, robust_se2, robust_se3),
          omit.stat = "f",
          add.lines = list(c("AIC", round(AIC1, 2), round(AIC2, 2),
                             round(AIC3, 2))))
```

**Statistical Significance**: The intercept and coefficients for _probconv_, _log(density)_ and _pctmin_ are statistically significant at a significance level of 0.01. _probsen_ is statistically significant at a signifcance level of 0.1.

**Practical Significance**

******************************
Several variables standout as good candidates for an initial model attempting to understand the determinants of crime. These include the proportion of crimes resulting in arrests, _probarr_, the average prison sentence length, _avgsen_, police per capita, _police_, people per square mile, _density_, average wages (which are spread across several variables), and the proportion of males between ages 15 and 24, _ymale_. 

The proportion of crimes resulting in arrests, _probarr_, should negatively influence crime rate, intuitively, in the same way that increased ticketing on highways should reduce speeding. The histogram and number of observations are shown below.

The histogram above shows an approximately normal distribution. With 90 observations, the central limit theorem (CLT) can be relied upon to make an inference about this variable's regression coefficient as it corresponds to the population.

The average prison sentence length, _avgsen_, like _probarr_, should also negatively influence crime rate, as longer sentences increase the consequences to committing a crime.


The prison sentence length distribution, above, is approximately normal with a positive skew, likely due to the fact that the metric is zero-bounded. As with _probarr_, 90 observations is sufficient to rely on the CLT for population inferences.







The variable describing people per square mile, _density_, is a more detailed indicator of urban versus non-urban environments than the boolean varianble, _urban_. Density should also influence crime rate, either positively or negatively, since 'haves' and 'havenots' become closer together at higher densities, yet higher density areas also result in more witnesses to deter face-to-face crime.



Density's distribution has a strong positive skew, due to the zero bound. Despite the skew, the CLT can still be relied upon for population inferences, as the number of observations, 90, is sufficient.

Average wages, _avgwage_ is a variable created below by concatenating each wage variable in the dataset together. In this way, average wages for each county can be modeled against crime.


```{r}
avgwage = (wagecon + wagetuc + wagetrd + wagefir +
        wageser + wagemfg + wagefed + wagesta + 
                wageloc)/9

length(avgwage)
hist(avgwage, breaks = 20, main = "Average Wage", xlab = "Wage")
```
Average wage also has an approximately normal distribution, with a positive skew. 
********************************************************



Omitted variable bias

Because of the manner in which population density influences living conditions (ie: houses vs. apartment complexes), it is also likely to be correlated with both poverty and crime. Studies have found that "more densely populated neighborhoods tend to be poorer, have higher percentages of persons in the age range of 12 to 20, have larger concentrations of single-parent households". Since our dataset does not provide us good information on income level in each county or unemployment rate in each county, the omitted variable bias is showing up in high coefficient for density. Since poverty level has a high positive correlation with density as well as crime, the coefficient of density has an upward bias.


Conclusion

Although this analysis provides an interesting outlook on the relationship between crime , it has various shortcomings. The small scope of this examination yields a lack of some key independent variables and results omitted variable bias. For a more accurate picture of the relationship between poverty and crime, variables such as income level, family structure, climate, divorce rate, unemployment rate, and educational attainment could be added. Crime may be influenced by trends within a city that cannot be measured by any variables, so time series data of the counties could help capture characteristics specific to a certain Area and would be helpful in this study.








