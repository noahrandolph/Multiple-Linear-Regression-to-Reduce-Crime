---
title: "Lab 4: Reducing Crime"
author: "Asha Anju, Anamika Sinha, Noah Randolph"
date: "8/14/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

...

## Load Data 

We first load the data and note any anomalies, such as missing values, top-coded or bottom-coded variables, or not-applicable values.

```{r load data}
library(sandwich)
library(lmtest)
library(car)
library(stargazer)

#setwd("~/Documents/W203_Statistics/Labs/Lab_4/Lab4Repository")
CrDat = read.csv("crime_v2.csv")

attach(CrDat)
```



##  Exploratory Data Analysis
We begin with a summary of the data.
```{r}
summary(CrDat)
nrow(CrDat)
ncol(CrDat)
```
##Observations: 
There are 90 observations across 25 variables. There are no missing values and the data in each variable make sense given the variable types, except for values in _probsen_ and _probconv_, which both show proportions that are greater than 1. This may be due to differences in ways the variable is reported from across the state. We will note this but would like to keep them in our analysis as they may have significant information. We also note that the maximum density is 8.8 people per square mile which indicates that we may be looking at a rural state. The crime rate proportions are low decimal values, so we will rescale it later to improve interpretation. Also, _avgsen_ has a maximum of 20 days which suggests that we have a vast majority of petty crimes. We notice a very high value of 2177.1 dollars for _wageser_ which is an extreme outlier since difference between this value and the third quartile is greater than three times the interquartile range. 

##Model proposal
Our dataset has _probsen_, _probconv_, _probarr_ , _mix_  _avgsen_, _police_  variables which represent the criminal justice system. We have variables like _wage & _tax_ which are representative of economic conditions. We also have _pctmix_, _ymale_, _density_, _urban_ variables which fall under demographic factors. There are three indicator variables representing regions(west, central) and cities(urban). 

Crime rate depends on the effectiveness of the criminal justice system and economic factors. Criminal justice systems reduce crime through deterence. Therefore increases in police, arrests, convictions, crime sentencing, and prison sentence length should reduce crime rate. Therefore, we explore these variables.

We first look at the response variable, _crime_, representing the number of each counties' crimes committed per person. The common way to report crimes is per 1000 people, so we'll do that here for readability.

```{r fig.height = 3, fig.width = 4}
scaledcrime = crime*1000
hist(scaledcrime, breaks = 20, main = "County Crime Rates", 
     xlab = "crimes committed per 1000 people")
```

The histogram above shows a positive skew. The distribution is continuous. No outliars are present.

To further review the explanatory criminal justice variables, we check their histograms.

```{r}
hist(police, breaks = 20, main = "Police Per Capita",
     xlab = "police per capita")
```

```{r}
hist(probarr, breaks = 16, 
     main = "Proportion of County Crimes Resulting in Arrests",
     xlab = "Proportion of Crimes Resulting in Arrests")
```

```{r}
hist(probconv, breaks = 10, main = "Proportion Being Convicted After Arrest",
     xlab = "Proportion")
```

```{r}
hist(probsen, breaks = 20, main = "Proportion Being Sentenced After Conviction",
     xlab = "Proportion")
```

```{r}
hist(mix, breaks = 20, main = "Ratio of Face-to-Face/All Other Crime",
     xlab = "Ratio")
```

### Observations:
_police_:


 Wage would be a good economic indicator but in our dataset, wage is broken up into eight different variables based on sector. In the absence of sector weights, it is difficult to create a meaningful average variable. We tried various ways to interpret the given information by taking an average of all the wage variables and also the wage range in each county to understand wage effect on crime.







Several variables standout as good candidates for an initial model attempting to understand the determinants of crime. These include the proportion of crimes resulting in arrests, _probarr_, the average prison sentence length, _avgsen_, police per capita, _police_, people per square mile, _density_, average wages (which are spread across several variables), and the proportion of males between ages 15 and 24, _ymale_. 

The proportion of crimes resulting in arrests, _probarr_, should negatively influence crime rate, intuitively, in the same way that increased ticketing on highways should reduce speeding. The histogram and number of observations are shown below.



The histogram above shows an approximately normal distribution. With 90 observations, the central limit theorem (CLT) can be relied upon to make an inference about this variable's regression coefficient as it corresponds to the population.

The average prison sentence length, _avgsen_, like _probarr_, should also negatively influence crime rate, as longer sentences increase the consequences to committing a crime.






The prison sentence length distribution, above, is approximately normal with a positive skew, likely due to the fact that the metric is zero-bounded. As with _probarr_, 90 observations is sufficient to rely on the CLT for population inferences.

Police per capita, _police_, should have negative influence on county crime rates, since their presence is generally thought of as a deterence.




There is a large spike at 0.001 to 0.002 police per capita and short tails on either side, with a positive skew, including an outliar at 0.009 to 0.010 police per capita. We investigate that observation further below.

```{r}
CrDat[police > 0.005, ]
```

Noting that it is the same county which had values greater than 1 for _probsen_ and _probconv_ (which are now coded _NA_), the rest of county data does not indicate anything to be invalid. We note that the average sentence length of this county is maximum of all the counties, as seen in the initial summary, and the percent minority is the lowest of all the counties.

The variable describing people per square mile, _density_, is a more detailed indicator of urban versus non-urban environments than the boolean varianble, _urban_. Density should also influence crime rate, either positively or negatively, since 'haves' and 'havenots' become closer together at higher densities, yet higher density areas also result in more witnesses to deter face-to-face crime.

```{r}
length(density)

hist(density, breaks = 20, main = "Density",
     xlab = "people per square mile")
```

Density's distribution has a strong positive skew, due to the zero bound. Despite the skew, the CLT can still be relied upon for population inferences, as the number of observations, 90, is sufficient.

Average wages, _avgwage_ is a variable created below by concatenating each wage variable in the dataset together. In this way, average wages for each county can be modeled against crime.

```{r}
avgwage = (wagecon + wagetuc + wagetrd + wagefir +
        wageser + wagemfg + wagefed + wagesta + 
                wageloc)/9

length(avgwage)
hist(avgwage, breaks = 20, main = "Average Wage", xlab = "Wage")
```

Average wage also has an approximately normal distribution, with a positive skew. 

```{r}
hist(tax, breaks = 20)
```


```{r}
hist(ymale, breaks = 20)
```

```{r}
hist(pctmin, breaks = 20)
```

```{r}
scatterplotMatrix(~ log(ymale) + log(police) + pctmin +
                          density)
```

```{r}
scatterplotMatrix(~ log(police) + probarr + probconv +
                          probsen)
```

```{r}
plot(jitter(urban), jitter(west))
```

```{r}
plot(jitter(urban), jitter(central))
```

#### Model 1

```{r}

scaledpolice = police*1000
pctarr = probarr*100
pctconv = probconv*100
pctsen = probsen*100

model1 = lm(scaledcrime ~ pctsen + pctconv + density)
AIC1 = AIC(model1)
plot(model1)
summary(model1)
vif(model1)

# hist(model3$residuals, breaks = 50)
# shapiro.test(model3$residuals)
# bptest(model3)
```

#### Model 2

```{r}
model2 = lm(scaledcrime ~ scaledpolice + pctsen + pctconv + density + pctmin)
AIC2 = AIC(model2)
plot(model2)
vif(model2)
summary(model2)
```

#### Model 3

```{r}
model3 = lm(scaledcrime ~ scaledpolice + pctsen + pctconv + density + pctmin +
                    pctarr + ymale + avgsen +  mix + avgwage + central + west +
                    tax)
AIC3 = AIC(model3)
plot(model3)
vif(model3)
summary(model3)
```



```{r}
# Adjust standard errors
cov1 = vcovHC(model1)
robust_se1 = sqrt(diag(cov1))
cov2 = vcovHC(model2)
robust_se2 = sqrt(diag(cov2))
cov3 = vcovHC(model3)
robust_se3 = sqrt(diag(cov3))

# Adjust F statistic 
wald_results <- waldtest(model1, vcov = cov1)

stargazer(model1, model2, model3, type = 'text', intercept.bottom = FALSE,
          se        = list(robust_se1, robust_se2, robust_se3),
          omit.stat = "f",
          add.lines = list(c("AIC", round(AIC1, 2), round(AIC2, 2), 
                             round(AIC3, 2))))
```
```{r}
model_x = lm(scaledcrime ~ pctsen + density + pctconv)
AIC1 = AIC(model_x)
plot(model_x)
summary(model_x)
vif(model_x)
coeftest(model_x, vcov=vcovHC)
```
##First model
```{r}
model1 = lm(scaledcrime ~ density + pctconv)
AIC1 = AIC(model1)
plot(model1)
summary(model1)
vif(model1)
coeftest(model1, vcov=vcovHC)
```




#### Model 2

```{r}
model2 = lm(scaledcrime ~ density +  pctconv + scaledpolice+ pctsen  + pctmin)
AIC2 = AIC(model2)
plot(model2)
vif(model2)
summary(model2)
coeftest(model2, vcov=vcovHC)
```

```{r}
AIC1
AIC2
```
```{r}
# Adjust standard errors
cov1 = vcovHC(model1)
robust_se1 = sqrt(diag(cov1))
cov2 = vcovHC(model2)
robust_se2 = sqrt(diag(cov2))
cov3 = vcovHC(model3)
robust_se3 = sqrt(diag(cov3))

# Adjust F statistic 
wald_results <- waldtest(model1, vcov = cov1)

stargazer(model1, model2, model3, type = 'text', intercept.bottom = FALSE,
          se        = list(robust_se1, robust_se2, robust_se3),
          omit.stat = "f",
          add.lines = list(c("AIC", round(AIC1, 2), round(AIC2, 2), 
                             round(AIC3, 2))))
```

